"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[551],{5887:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>r,contentTitle:()=>s,default:()=>p,frontMatter:()=>l,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-3-ai-robot-brain/chapter-3-6-nav2-path-planning","title":"Nav2 Path Planning and Navigation","description":"Goal","source":"@site/docs/module-3-ai-robot-brain/chapter-3-6-nav2-path-planning.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/chapter-3-6-nav2-path-planning","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-3-6-nav2-path-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/physical-ai-humanoid-robotics-book/tree/main/docs/module-3-ai-robot-brain/chapter-3-6-nav2-path-planning.md","tags":[],"version":"current","frontMatter":{"id":"chapter-3-6-nav2-path-planning","title":"Nav2 Path Planning and Navigation","sidebar_label":"Nav2 Path Planning and Navigation"},"sidebar":"book","previous":{"title":"Synthetic Data Generation","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation"},"next":{"title":"Vision-Language-Action Systems","permalink":"/physical-ai-humanoid-robotics-book/docs/module-4-vision-language-action/chapter-4-1-vla-systems"}}');var t=a(4848),i=a(8453);const l={id:"chapter-3-6-nav2-path-planning",title:"Nav2 Path Planning and Navigation",sidebar_label:"Nav2 Path Planning and Navigation"},s="Nav2 Path Planning and Navigation",r={},c=[{value:"Goal",id:"goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Overview",id:"overview",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Step-by-Step Breakdown",id:"step-by-step-breakdown",level:2},{value:"Code Examples",id:"code-examples",level:2},{value:"Diagrams",id:"diagrams",level:2},{value:"Case Study",id:"case-study",level:2},{value:"References",id:"references",level:2},{value:"Review Questions",id:"review-questions",level:2},{value:"Practical Exercises",id:"practical-exercises",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"nav2-path-planning-and-navigation",children:"Nav2 Path Planning and Navigation"})}),"\n",(0,t.jsx)(e.h2,{id:"goal",children:"Goal"}),"\n",(0,t.jsx)(e.p,{children:"Implement advanced path planning and navigation systems for humanoid robots using the Navigation2 (Nav2) framework integrated with NVIDIA Isaac tools, enabling autonomous movement in complex environments."}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand the Navigation2 (Nav2) architecture and components"}),"\n",(0,t.jsx)(e.li,{children:"Configure Nav2 for humanoid robot navigation"}),"\n",(0,t.jsx)(e.li,{children:"Implement global and local planners for humanoid kinematics"}),"\n",(0,t.jsx)(e.li,{children:"Integrate Nav2 with Isaac perception systems"}),"\n",(0,t.jsx)(e.li,{children:"Configure navigation behaviors for complex humanoid movements"}),"\n",(0,t.jsx)(e.li,{children:"Validate navigation performance in simulation and real environments"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(e.p,{children:"Navigation2 (Nav2) is the state-of-the-art navigation framework for ROS 2, designed to provide robust and flexible navigation capabilities for mobile robots. For humanoid robots, Nav2 offers specialized tools and configurations to handle the unique challenges of bipedal locomotion, complex kinematics, and human-like navigation patterns. When integrated with NVIDIA Isaac's perception and AI capabilities, Nav2 enables humanoid robots to navigate complex environments with advanced obstacle avoidance and path planning capabilities."}),"\n",(0,t.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Navigation2 (Nav2)"}),": ROS 2 navigation framework"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Global Planner"}),": Long-term path planning from start to goal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Local Planner"}),": Short-term obstacle avoidance and path following"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Costmaps"}),": Representing environment traversability"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Behavior Trees"}),": Composable navigation behaviors"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Recovery Behaviors"}),": Handling navigation failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Humanoid Kinematics"}),": Specialized navigation for bipedal robots"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"step-by-step-breakdown",children:"Step-by-Step Breakdown"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Nav2 Architecture Understanding"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Learn about Nav2 components and their interactions"}),"\n",(0,t.jsx)(e.li,{children:"Understand the behavior tree-based navigation system"}),"\n",(0,t.jsx)(e.li,{children:"Configure Nav2 parameters for humanoid robots"}),"\n",(0,t.jsx)(e.li,{children:"Set up the navigation stack"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Costmap Configuration"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Configure global and local costmaps"}),"\n",(0,t.jsx)(e.li,{children:"Set up obstacle inflation and filtering"}),"\n",(0,t.jsx)(e.li,{children:"Configure voxel grid for 3D obstacle representation"}),"\n",(0,t.jsx)(e.li,{children:"Optimize costmap parameters for humanoid navigation"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Global Planner Implementation"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Configure A* or Dijkstra planners for humanoid kinematics"}),"\n",(0,t.jsx)(e.li,{children:"Set up potential field or other advanced planners"}),"\n",(0,t.jsx)(e.li,{children:"Configure path smoothing and optimization"}),"\n",(0,t.jsx)(e.li,{children:"Handle dynamic obstacles and replanning"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Local Planner Configuration"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Set up trajectory rollout planners (DWA, TEB)"}),"\n",(0,t.jsx)(e.li,{children:"Configure velocity and acceleration limits for humanoid"}),"\n",(0,t.jsx)(e.li,{children:"Implement obstacle avoidance strategies"}),"\n",(0,t.jsx)(e.li,{children:"Optimize for real-time performance"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Behavior Tree Customization"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Design behavior trees for humanoid navigation"}),"\n",(0,t.jsx)(e.li,{children:"Implement custom navigation actions"}),"\n",(0,t.jsx)(e.li,{children:"Configure recovery behaviors"}),"\n",(0,t.jsx)(e.li,{children:"Optimize decision-making processes"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Integration with Isaac"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Integrate Nav2 with Isaac perception systems"}),"\n",(0,t.jsx)(e.li,{children:"Connect to Isaac's VSLAM and mapping capabilities"}),"\n",(0,t.jsx)(e.li,{children:"Configure sensor fusion for navigation"}),"\n",(0,t.jsx)(e.li,{children:"Validate navigation performance"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# Example Nav2 integration for humanoid robot navigation\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionClient\nfrom rclpy.qos import QoSProfile\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom nav2_msgs.action import NavigateToPose\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom sensor_msgs.msg import LaserScan\nfrom tf2_ros import TransformException\nfrom tf2_ros.buffer import Buffer\nfrom tf2_ros.transform_listener import TransformListener\nfrom tf2_geometry_msgs import PoseStamped\nimport tf_transformations\nimport numpy as np\nimport math\nfrom typing import List, Tuple, Optional\n\nclass HumanoidNav2Interface(Node):\n    def __init__(self):\n        super().__init__('humanoid_nav2_interface')\n\n        # TF buffer and listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Navigation parameters for humanoid robot\n        self.nav_params = {\n            'max_linear_vel': 0.4,  # Slower for stability\n            'max_angular_vel': 0.3,\n            'min_linear_vel': 0.1,\n            'min_angular_vel': 0.05,\n            'goal_tolerance': 0.3,  # Larger for humanoid stability\n            'yaw_tolerance': 0.2,\n            'footprint_radius': 0.3,  # Humanoid robot footprint\n            'inflation_radius': 0.5,  # Extra safety for humanoid\n            'robot_base_frame': 'base_link',\n            'global_frame': 'map'\n        }\n\n        # Initialize navigation action client\n        self.nav_to_pose_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n\n        # Initialize publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.path_pub = self.create_publisher(Path, '/nav2/path', 10)\n        self.velocity_pub = self.create_publisher(Twist, '/nav2/velocity', 10)\n\n        # Navigation state\n        self.current_goal = None\n        self.is_navigating = False\n        self.navigation_active = False\n\n        # Robot state\n        self.robot_pose = None\n        self.robot_twist = None\n\n        # Subscribers for robot state\n        self.odom_sub = self.create_subscription(\n            PoseStamped, '/odom', self.odom_callback, 10\n        )\n\n        # Timer for navigation monitoring\n        self.nav_monitor_timer = self.create_timer(0.5, self.navigation_monitor)\n\n        self.get_logger().info('Humanoid Nav2 Interface initialized')\n\n    def odom_callback(self, msg):\n        \"\"\"Update robot pose from odometry\"\"\"\n        self.robot_pose = msg.pose\n\n    def send_navigation_goal(self, x: float, y: float, theta: float = 0.0) -> bool:\n        \"\"\"Send navigation goal to Nav2\"\"\"\n        # Wait for action server\n        if not self.nav_to_pose_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error('Navigation action server not available')\n            return False\n\n        # Create navigation goal\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = self.nav_params['global_frame']\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n        goal_msg.pose.pose.position.x = float(x)\n        goal_msg.pose.pose.position.y = float(y)\n        goal_msg.pose.pose.position.z = 0.0\n\n        # Convert angle to quaternion\n        from tf_transformations import quaternion_from_euler\n        quat = quaternion_from_euler(0, 0, theta)\n        goal_msg.pose.pose.orientation.x = quat[0]\n        goal_msg.pose.pose.orientation.y = quat[1]\n        goal_msg.pose.pose.orientation.z = quat[2]\n        goal_msg.pose.pose.orientation.w = quat[3]\n\n        # Send goal\n        self.current_goal = goal_msg\n        self.is_navigating = True\n\n        self.get_logger().info(f'Sending navigation goal: ({x}, {y}, {theta})')\n\n        # Send async goal\n        self._send_goal_future = self.nav_to_pose_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.navigation_feedback\n        )\n\n        self._send_goal_future.add_done_callback(self.goal_response_callback)\n        return True\n\n    def goal_response_callback(self, future):\n        \"\"\"Handle goal response\"\"\"\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().info('Goal rejected')\n            self.is_navigating = False\n            return\n\n        self.get_logger().info('Goal accepted')\n        self.navigation_active = True\n\n        # Get result future\n        self._get_result_future = goal_handle.get_result_async()\n        self._get_result_future.add_done_callback(self.get_result_callback)\n\n    def get_result_callback(self, future):\n        \"\"\"Handle navigation result\"\"\"\n        result = future.result().result\n        self.navigation_active = False\n        self.is_navigating = False\n\n        if result:\n            self.get_logger().info('Navigation completed successfully')\n        else:\n            self.get_logger().info('Navigation failed')\n\n    def navigation_feedback(self, feedback_msg):\n        \"\"\"Handle navigation feedback\"\"\"\n        feedback = feedback_msg.feedback\n        # Process feedback as needed\n        self.get_logger().debug(f'Navigation progress: {feedback.distance_remaining:.2f}m remaining')\n\n    def navigation_monitor(self):\n        \"\"\"Monitor navigation state and provide humanoid-specific behaviors\"\"\"\n        if not self.is_navigating:\n            return\n\n        # Check robot state and adjust behavior if needed\n        if self.robot_pose:\n            # Calculate distance to goal if available\n            if self.current_goal:\n                goal_pos = self.current_goal.pose.pose.position\n                robot_pos = self.robot_pose.position\n\n                distance = math.sqrt(\n                    (goal_pos.x - robot_pos.x)**2 +\n                    (goal_pos.y - robot_pos.y)**2\n                )\n\n                self.get_logger().debug(f'Distance to goal: {distance:.2f}m')\n\n                # Adjust behavior based on distance or other factors\n                if distance < self.nav_params['goal_tolerance']:\n                    self.get_logger().info('Reached navigation goal')\n                    self.is_navigating = False\n                    self.navigation_active = False\n\n    def stop_navigation(self):\n        \"\"\"Stop current navigation\"\"\"\n        self.is_navigating = False\n        self.navigation_active = False\n\n        # Send stop command\n        stop_cmd = Twist()\n        self.cmd_vel_pub.publish(stop_cmd)\n\n        self.get_logger().info('Navigation stopped')\n\nclass Nav2ConfigurationNode(Node):\n    \"\"\"Node to configure Nav2 parameters for humanoid robot\"\"\"\n\n    def __init__(self):\n        super().__init__('nav2_configurator')\n\n        # Publisher for dynamic parameters\n        self.param_client = self.create_client(\n            SetParameters, '/controller_server/set_parameters'\n        )\n\n        # Configure Nav2 for humanoid robot\n        self.configure_humanoid_nav2()\n\n    def configure_humanoid_nav2(self):\n        \"\"\"Configure Nav2 parameters specifically for humanoid robot\"\"\"\n\n        # Humanoid-specific parameters\n        humanoid_params = {\n            # Robot description for kinematic constraints\n            'robot_radius': 0.3,  # meters\n            'footprint_padding': 0.1,  # extra safety\n\n            # Velocity limits for stable walking\n            'max_linear_vel': 0.4,  # m/s (slower for stability)\n            'min_linear_vel': 0.1,\n            'max_angular_vel': 0.3,  # rad/s\n            'min_angular_vel': 0.05,\n\n            # Acceleration limits for humanoid dynamics\n            'max_linear_accel': 0.2,  # m/s\xb2\n            'max_angular_accel': 0.2,  # rad/s\xb2\n\n            # Path planning parameters\n            'planner_frequency': 5.0,  # Hz\n            'controller_frequency': 20.0,  # Hz (higher for stability)\n\n            # Costmap parameters\n            'inflation_radius': 0.5,  # Larger for humanoid safety\n            'cost_scaling_factor': 5.0,  # More aggressive cost scaling\n\n            # Goal tolerance (larger for humanoid stability)\n            'goal_check_tolerance': 0.3,  # meters\n            'yaw_goal_tolerance': 0.2,   # radians\n        }\n\n        self.get_logger().info('Configured Nav2 for humanoid robot')\n        self.apply_nav2_parameters(humanoid_params)\n\n    def apply_nav2_parameters(self, params):\n        \"\"\"Apply parameters to Nav2 nodes\"\"\"\n        # In a real implementation, this would use ROS 2 parameter services\n        # to configure Nav2 components dynamically\n        for param_name, param_value in params.items():\n            self.get_logger().debug(f'Setting {param_name} = {param_value}')\n\nclass HumanoidLocalPlanner(Node):\n    \"\"\"Custom local planner optimized for humanoid robots\"\"\"\n\n    def __init__(self):\n        super().__init__('humanoid_local_planner')\n\n        # Subscribers\n        self.global_path_sub = self.create_subscription(\n            Path, '/plan', self.global_path_callback, 10\n        )\n        self.laser_sub = self.create_subscription(\n            LaserScan, '/scan', self.laser_callback, 10\n        )\n        self.odom_sub = self.create_subscription(\n            PoseStamped, '/odom', self.odom_callback, 10\n        )\n\n        # Publishers\n        self.velocity_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.local_plan_pub = self.create_publisher(Path, '/local_plan', 10)\n\n        # Local planner parameters\n        self.planner_params = {\n            'local_window_size': 3.0,  # meters\n            'max_vel_x': 0.4,  # m/s\n            'min_vel_x': 0.05,\n            'max_vel_theta': 0.3,  # rad/s\n            'min_vel_theta': 0.02,\n            'acc_lim_x': 0.2,  # m/s\xb2\n            'acc_lim_theta': 0.2,  # rad/s\xb2\n            'xy_goal_tolerance': 0.3,  # meters\n            'yaw_goal_tolerance': 0.2,  # radians\n        }\n\n        # State variables\n        self.global_path = []\n        self.current_pose = None\n        self.laser_data = None\n        self.current_velocity = Twist()\n\n        # Timer for local planning\n        self.planning_timer = self.create_timer(0.05, self.local_planning_callback)  # 20 Hz\n\n        self.get_logger().info('Humanoid Local Planner initialized')\n\n    def global_path_callback(self, msg: Path):\n        \"\"\"Update global path from Nav2\"\"\"\n        self.global_path = msg.poses\n\n    def laser_callback(self, msg: LaserScan):\n        \"\"\"Update laser data for obstacle detection\"\"\"\n        self.laser_data = msg\n\n    def odom_callback(self, msg: PoseStamped):\n        \"\"\"Update robot pose\"\"\"\n        self.current_pose = msg.pose\n\n    def local_planning_callback(self):\n        \"\"\"Main local planning callback\"\"\"\n        if not self.current_pose or not self.global_path:\n            return\n\n        # Get local path segment\n        local_path = self.get_local_path_segment()\n\n        # Check for obstacles\n        if self.laser_data and self.check_for_obstacles():\n            # Execute obstacle avoidance\n            velocity_cmd = self.obstacle_avoidance_behavior()\n        else:\n            # Follow path normally\n            velocity_cmd = self.follow_path(local_path)\n\n        # Publish velocity command\n        self.velocity_pub.publish(velocity_cmd)\n        self.current_velocity = velocity_cmd\n\n        # Publish local plan for visualization\n        if local_path:\n            local_path_msg = Path()\n            local_path_msg.header.stamp = self.get_clock().now().to_msg()\n            local_path_msg.header.frame_id = 'map'\n            local_path_msg.poses = local_path\n            self.local_plan_pub.publish(local_path_msg)\n\n    def get_local_path_segment(self) -> List[PoseStamped]:\n        \"\"\"Get path segment within local window\"\"\"\n        if not self.current_pose or not self.global_path:\n            return []\n\n        local_path = []\n        current_pos = self.current_pose.position\n\n        for pose_stamped in self.global_path:\n            # Calculate distance to pose\n            dx = pose_stamped.pose.position.x - current_pos.x\n            dy = pose_stamped.pose.position.y - current_pos.y\n            distance = math.sqrt(dx*dx + dy*dy)\n\n            if distance <= self.planner_params['local_window_size']:\n                local_path.append(pose_stamped)\n\n        return local_path\n\n    def check_for_obstacles(self) -> bool:\n        \"\"\"Check laser data for obstacles in path\"\"\"\n        if not self.laser_data:\n            return False\n\n        # Check if there are obstacles within humanoid's path\n        min_range = min(self.laser_data.ranges) if self.laser_data.ranges else float('inf')\n        return min_range < 0.8  # threshold for humanoid safety\n\n    def obstacle_avoidance_behavior(self) -> Twist:\n        \"\"\"Execute obstacle avoidance behavior\"\"\"\n        cmd_vel = Twist()\n\n        # Simple obstacle avoidance: turn away from obstacles\n        if self.laser_data:\n            # Find the direction with maximum clearance\n            ranges = np.array(self.laser_data.ranges)\n            valid_ranges = ranges[np.isfinite(ranges)]\n\n            if len(valid_ranges) > 0:\n                # Turn toward the clearest direction\n                max_idx = np.argmax(ranges)\n                angle_increment = self.laser_data.angle_increment\n                angle_to_max = self.laser_data.angle_min + max_idx * angle_increment\n\n                cmd_vel.angular.z = max(min(angle_to_max * 0.5,\n                                          self.planner_params['max_vel_theta']),\n                                      -self.planner_params['max_vel_theta'])\n\n        return cmd_vel\n\n    def follow_path(self, local_path: List[PoseStamped]) -> Twist:\n        \"\"\"Follow the local path segment\"\"\"\n        cmd_vel = Twist()\n\n        if not local_path:\n            return cmd_vel\n\n        # Get the next waypoint to follow\n        target_pose = local_path[0].pose if local_path else None\n        if not target_pose:\n            return cmd_vel\n\n        # Calculate direction to target\n        current_pos = self.current_pose.position\n        target_pos = target_pose.position\n\n        dx = target_pos.x - current_pos.x\n        dy = target_pos.y - current_pos.y\n        distance = math.sqrt(dx*dx + dy*dy)\n\n        # Calculate desired heading\n        desired_theta = math.atan2(dy, dx)\n\n        # Get current orientation\n        from tf_transformations import euler_from_quaternion\n        current_orientation = [\n            self.current_pose.orientation.x,\n            self.current_pose.orientation.y,\n            self.current_pose.orientation.z,\n            self.current_pose.orientation.w\n        ]\n        current_euler = euler_from_quaternion(current_orientation)\n        current_theta = current_euler[2]\n\n        # Calculate heading error\n        heading_error = desired_theta - current_theta\n        # Normalize angle to [-pi, pi]\n        while heading_error > math.pi:\n            heading_error -= 2 * math.pi\n        while heading_error < -math.pi:\n            heading_error += 2 * math.pi\n\n        # Set velocities\n        if abs(heading_error) > 0.1:  # 0.1 rad tolerance\n            cmd_vel.angular.z = max(min(heading_error * 1.0,\n                                      self.planner_params['max_vel_theta']),\n                                  -self.planner_params['max_vel_theta'])\n        else:\n            if distance > self.planner_params['xy_goal_tolerance']:\n                cmd_vel.linear.x = max(min(distance * 0.5,\n                                         self.planner_params['max_vel_x']),\n                                     self.planner_params['min_vel_x'])\n\n        return cmd_vel\n\ndef main(args=None):\n    \"\"\"Main function to run the Nav2 interface\"\"\"\n    rclpy.init(args=args)\n\n    # Create nodes\n    nav_interface = HumanoidNav2Interface()\n    nav_config = Nav2ConfigurationNode()\n    local_planner = HumanoidLocalPlanner()\n\n    try:\n        # Example: Send a navigation goal after startup\n        import time\n        time.sleep(2)  # Wait for connections\n\n        # Send a test goal\n        nav_interface.send_navigation_goal(2.0, 2.0, 0.0)\n\n        # Spin all nodes\n        executor = rclpy.executors.MultiThreadedExecutor()\n        executor.add_node(nav_interface)\n        executor.add_node(nav_config)\n        executor.add_node(local_planner)\n\n        executor.spin()\n\n    except KeyboardInterrupt:\n        nav_interface.get_logger().info('Shutting down Nav2 interface')\n    finally:\n        nav_interface.destroy_node()\n        nav_config.destroy_node()\n        local_planner.destroy_node()\n        rclpy.shutdown()\n\n# Isaac-specific Nav2 integration\nclass IsaacNav2Integrator(Node):\n    \"\"\"Node to integrate Nav2 with Isaac perception systems\"\"\"\n\n    def __init__(self):\n        super().__init__('isaac_nav2_integrator')\n\n        # Subscribers for Isaac perception data\n        self.vslam_pose_sub = self.create_subscription(\n            PoseStamped, '/vslam/pose', self.vslam_pose_callback, 10\n        )\n        self.semantic_map_sub = self.create_subscription(\n            OccupancyGrid, '/semantic_map', self.semantic_map_callback, 10\n        )\n\n        # Publishers to Nav2\n        self.nav_odom_pub = self.create_publisher(\n            Odometry, '/nav2/odom', 10\n        )\n        self.nav_costmap_pub = self.create_publisher(\n            OccupancyGrid, '/nav2/costmap', 10\n        )\n\n        self.get_logger().info('Isaac Nav2 Integrator initialized')\n\n    def vslam_pose_callback(self, msg: PoseStamped):\n        \"\"\"Handle VSLAM pose updates\"\"\"\n        # Convert VSLAM pose to Nav2-compatible odometry\n        odom_msg = Odometry()\n        odom_msg.header = msg.header\n        odom_msg.pose.pose = msg.pose\n        # Add velocity estimation if available\n\n        self.nav_odom_pub.publish(odom_msg)\n\n    def semantic_map_callback(self, msg: OccupancyGrid):\n        \"\"\"Handle semantic map updates from Isaac\"\"\"\n        # Forward semantic map to Nav2 costmap\n        self.nav_costmap_pub.publish(msg)\n\n    def setup_isaac_nav2_bridge(self):\n        \"\"\"Setup the integration between Isaac and Nav2\"\"\"\n        # This would configure the data flow between Isaac perception\n        # systems and Nav2 navigation stack\n        pass\n"})}),"\n",(0,t.jsx)(e.h2,{id:"diagrams",children:"Diagrams"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Nav2 Architecture for Humanoid Robots:\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Nav2 Core      \u2502    \u2502  Perception     \u2502    \u2502  Humanoid       \u2502\n\u2502  (Action Server\u2502\u25c4\u2500\u2500\u25ba\u2502  Integration    \u2502\u25c4\u2500\u2500\u25ba\u2502  Controller     \u2502\n\u2502   Behavior      \u2502    \u2502  (Isaac VSLAM, \u2502    \u2502  (Walking, etc.)\u2502\n\u2502   Tree)         \u2502    \u2502   Semantic Map) \u2502    \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Global Planner \u2502    \u2502  Costmap        \u2502    \u2502  Local Planner  \u2502\n\u2502  (A*, Dijkstra) \u2502    \u2502  (Global,      \u2502    \u2502  (DWA, TEB)     \u2502\n\u2502                 \u2502    \u2502   Local)        \u2502    \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502     Path Execution      \u2502\n                    \u2502     (Velocity Control)  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nHumanoid Navigation Workflow:\n\nStart Goal \u2192 Global Planner \u2192 Local Planner \u2192 Velocity Control \u2192 Humanoid Robot\n              (Path Planning)  (Obstacle Avoid)  (Stable Walking)   (Execution)\n\nNav2 Behavior Tree Structure:\n\nroot\n\u251c\u2500\u2500 compute_path_to_pose (Global Planner)\n\u251c\u2500\u2500 follow_path (Local Planner)\n\u2502   \u251c\u2500\u2500 smooth_path\n\u2502   \u251c\u2500\u2500 regulate_linear_velocity\n\u2502   \u251c\u2500\u2500 compute_velocity_commands\n\u2502   \u2514\u2500\u2500 is_stuck\n\u2502       \u2514\u2500\u2500 recovery_node\n\u2502           \u251c\u2500\u2500 spin\n\u2502           \u251c\u2500\u2500 backup\n\u2502           \u2514\u2500\u2500 drive_on_heading\n\u2514\u2500\u2500 goal_reached\n"})}),"\n",(0,t.jsx)(e.h2,{id:"case-study",children:"Case Study"}),"\n",(0,t.jsx)(e.p,{children:"The integration of Nav2 with NVIDIA Isaac has enabled advanced navigation capabilities for humanoid robots in complex environments. In a demonstration by the NVIDIA Isaac team, a humanoid robot equipped with Isaac's perception stack and Nav2 navigation was able to autonomously navigate through a cluttered indoor environment, avoiding both static and dynamic obstacles while maintaining stable bipedal locomotion. The system leveraged Isaac's VSLAM for localization and semantic mapping, which was then fed into Nav2's costmap system to create detailed traversability maps. This integration allowed the humanoid robot to perform complex navigation tasks that would be challenging with traditional approaches."}),"\n",(0,t.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://navigation.ros.org/",children:"Navigation2 Documentation"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://navigation.ros.org/tutorials/index.html",children:"Nav2 Tutorials"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_navigation",children:"Isaac ROS Navigation Integration"})}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"What are the key differences between Nav2 and the original ROS navigation stack?"}),"\n",(0,t.jsx)(e.li,{children:"How does Nav2 handle the unique challenges of humanoid robot navigation?"}),"\n",(0,t.jsx)(e.li,{children:"What role do behavior trees play in Nav2's architecture?"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"practical-exercises",children:"Practical Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Configure Nav2 for a humanoid robot simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement a custom local planner for humanoid kinematics"}),"\n",(0,t.jsx)(e.li,{children:"Test navigation performance with different planner configurations"}),"\n",(0,t.jsx)(e.li,{children:"Integrate Isaac perception data with Nav2 costmaps"}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>l,x:()=>s});var o=a(6540);const t={},i=o.createContext(t);function l(n){const e=o.useContext(i);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:l(n.components),o.createElement(i.Provider,{value:e},n.children)}}}]);