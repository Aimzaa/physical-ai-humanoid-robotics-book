"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[36],{4845:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation","title":"Synthetic Data Generation","description":"Goal","source":"@site/docs/module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/physical-ai-humanoid-robotics-book/tree/main/docs/module-3-ai-robot-brain/chapter-3-5-synthetic-data-generation.md","tags":[],"version":"current","frontMatter":{"id":"chapter-3-5-synthetic-data-generation","title":"Synthetic Data Generation","sidebar_label":"Synthetic Data Generation"},"sidebar":"book","previous":{"title":"Perception and Navigation Systems","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-3-4-perception-navigation"},"next":{"title":"Nav2 Path Planning and Navigation","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/chapter-3-6-nav2-path-planning"}}');var i=a(4848),r=a(8453);const s={id:"chapter-3-5-synthetic-data-generation",title:"Synthetic Data Generation",sidebar_label:"Synthetic Data Generation"},o="Synthetic Data Generation",l={},d=[{value:"Goal",id:"goal",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Overview",id:"overview",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Step-by-Step Breakdown",id:"step-by-step-breakdown",level:2},{value:"Code Examples",id:"code-examples",level:2},{value:"Diagrams",id:"diagrams",level:2},{value:"Case Study",id:"case-study",level:2},{value:"References",id:"references",level:2},{value:"Review Questions",id:"review-questions",level:2},{value:"Practical Exercises",id:"practical-exercises",level:2}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"synthetic-data-generation",children:"Synthetic Data Generation"})}),"\n",(0,i.jsx)(n.h2,{id:"goal",children:"Goal"}),"\n",(0,i.jsx)(n.p,{children:"Learn to generate high-quality synthetic data using NVIDIA Isaac Sim for training AI models in humanoid robotics applications, reducing the need for real-world data collection."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand the principles and benefits of synthetic data generation"}),"\n",(0,i.jsx)(n.li,{children:"Configure Isaac Sim for synthetic data creation"}),"\n",(0,i.jsx)(n.li,{children:"Implement domain randomization techniques for robust AI models"}),"\n",(0,i.jsx)(n.li,{children:"Generate diverse datasets for perception and control tasks"}),"\n",(0,i.jsx)(n.li,{children:"Validate synthetic-to-real transfer performance"}),"\n",(0,i.jsx)(n.li,{children:"Optimize synthetic data generation pipelines"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Synthetic data generation is a critical capability for developing AI-powered humanoid robots, as it allows for the creation of large, diverse, and perfectly labeled datasets without the time and cost constraints of real-world data collection. NVIDIA Isaac Sim provides powerful tools for generating photorealistic synthetic data with accurate physics and lighting, enabling the training of robust AI models that can transfer effectively to real robots. This approach is particularly valuable for humanoid robots, which require extensive training on complex behaviors and interactions."}),"\n",(0,i.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Synthetic Data"}),": Computer-generated data that mimics real-world observations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Domain Randomization"}),": Varying simulation parameters to improve model robustness"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Physically-Based Rendering"}),": Accurate simulation of lighting and materials"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensor Simulation"}),": Modeling camera, LiDAR, and other sensor characteristics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data Annotation"}),": Automatic labeling of synthetic datasets"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reality Gap"}),": Differences between synthetic and real data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transfer Learning"}),": Adapting synthetic-trained models for real-world use"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-by-step-breakdown",children:"Step-by-Step Breakdown"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Synthetic Data Fundamentals"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand the benefits and limitations of synthetic data"}),"\n",(0,i.jsx)(n.li,{children:"Learn about different types of synthetic data (images, point clouds, etc.)"}),"\n",(0,i.jsx)(n.li,{children:"Study domain randomization techniques"}),"\n",(0,i.jsx)(n.li,{children:"Explore the synthetic-to-real transfer problem"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Isaac Sim Configuration"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Set up Isaac Sim for data generation"}),"\n",(0,i.jsx)(n.li,{children:"Configure rendering and physics parameters"}),"\n",(0,i.jsx)(n.li,{children:"Design diverse environments and scenarios"}),"\n",(0,i.jsx)(n.li,{children:"Optimize simulation performance"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Domain Randomization Implementation"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Randomize lighting conditions (intensity, color, position)"}),"\n",(0,i.jsx)(n.li,{children:"Vary material properties (textures, colors, reflectance)"}),"\n",(0,i.jsx)(n.li,{children:"Change camera parameters (position, angle, noise)"}),"\n",(0,i.jsx)(n.li,{children:"Modify environmental conditions (weather, occlusions)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Data Annotation Pipeline"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Implement automatic labeling systems"}),"\n",(0,i.jsx)(n.li,{children:"Generate ground truth data (depth, segmentation, bounding boxes)"}),"\n",(0,i.jsx)(n.li,{children:"Create metadata for each data sample"}),"\n",(0,i.jsx)(n.li,{children:"Validate annotation accuracy"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Dataset Generation"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Design diverse scenarios for humanoid robot tasks"}),"\n",(0,i.jsx)(n.li,{children:"Generate large-scale datasets efficiently"}),"\n",(0,i.jsx)(n.li,{children:"Implement data augmentation techniques"}),"\n",(0,i.jsx)(n.li,{children:"Organize data for different AI tasks"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Validation and Transfer"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Test synthetic-trained models on real data"}),"\n",(0,i.jsx)(n.li,{children:"Measure transfer performance metrics"}),"\n",(0,i.jsx)(n.li,{children:"Identify and address reality gaps"}),"\n",(0,i.jsx)(n.li,{children:"Optimize simulation parameters for better transfer"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example synthetic data generation pipeline using Isaac Sim\nimport carb\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.sensor import Camera\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nimport numpy as np\nimport cv2\nimport json\nimport os\nfrom PIL import Image\nimport random\nimport datetime\nfrom typing import Dict, List, Tuple, Any\n\nclass IsaacSyntheticDataGenerator:\n    def __init__(self, output_dir: str = \"synthetic_data\", num_samples: int = 1000):\n        \"\"\"\n        Initialize synthetic data generator for humanoid robot perception\n\n        Args:\n            output_dir: Directory to save generated data\n            num_samples: Number of samples to generate\n        \"\"\"\n        self.output_dir = output_dir\n        self.num_samples = num_samples\n        self.world = None\n        self.camera = None\n        self.robot = None\n        self.objects = []\n\n        # Create output directories\n        os.makedirs(os.path.join(output_dir, \"images\"), exist_ok=True)\n        os.makedirs(os.path.join(output_dir, \"labels\"), exist_ok=True)\n        os.makedirs(os.path.join(output_dir, \"metadata\"), exist_ok=True)\n\n        # Domain randomization parameters\n        self.domain_params = {\n            'lighting': {\n                'intensity_range': (100, 1000),\n                'color_temperature_range': (3000, 8000),\n                'direction_range': ((-1, -1, -1), (1, 1, 1))\n            },\n            'materials': {\n                'colors': [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)],\n                'textures': ['rough', 'smooth', 'metallic', 'matte'],\n                'reflectance_range': (0.0, 1.0)\n            },\n            'camera': {\n                'position_range': ((-2, -2, 1), (2, 2, 3)),\n                'angle_range': ((-0.5, -0.5, -1.5), (0.5, 0.5, 1.5)),\n                'noise_level_range': (0.0, 0.1)\n            },\n            'environment': {\n                'floor_textures': ['wood', 'tile', 'carpet', 'concrete'],\n                'background_objects': ['table', 'chair', 'box', 'plant']\n            }\n        }\n\n        # Initialize world\n        self._setup_world()\n\n        self.get_logger().info(f'Synthetic data generator initialized. Output dir: {output_dir}')\n\n    def _setup_world(self):\n        \"\"\"Setup Isaac Sim world for data generation\"\"\"\n        # Create world\n        self.world = World(stage_units_in_meters=1.0)\n\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n\n        # Add humanoid robot\n        robot_prim_path = \"/World/Robot\"\n        add_reference_to_stage(\n            usd_path=\"path/to/humanoid_robot.usd\",  # Replace with actual path\n            prim_path=robot_prim_path\n        )\n        self.robot = self.world.scene.add_robot(\n            Robot(prim_path=robot_prim_path, name=\"humanoid_robot\")\n        )\n\n        # Add camera\n        camera_prim_path = \"/World/Camera\"\n        self.camera = self.world.scene.add(Camera(\n            prim_path=camera_prim_path,\n            frequency=30,\n            resolution=(640, 480)\n        ))\n\n        # Set initial camera position\n        self.camera.set_world_pose(position=np.array([1.0, 0.0, 1.5]))\n\n        # Play the world\n        self.world.reset()\n        self.world.play()\n\n    def randomize_lighting(self):\n        \"\"\"Apply random lighting conditions\"\"\"\n        # In a real implementation, this would modify light sources in the scene\n        # For demonstration, we'll just log the changes\n        intensity = random.uniform(*self.domain_params['lighting']['intensity_range'])\n        color_temp = random.uniform(*self.domain_params['lighting']['color_temperature_range'])\n\n        self.get_logger().debug(f'Applied random lighting: intensity={intensity}, color_temp={color_temp}')\n\n    def randomize_materials(self):\n        \"\"\"Apply random material properties\"\"\"\n        # Randomize object materials\n        color = random.choice(self.domain_params['materials']['colors'])\n        texture = random.choice(self.domain_params['materials']['textures'])\n        reflectance = random.uniform(*self.domain_params['materials']['reflectance_range'])\n\n        self.get_logger().debug(f'Applied random materials: color={color}, texture={texture}, reflectance={reflectance}')\n\n    def randomize_camera(self):\n        \"\"\"Apply random camera parameters\"\"\"\n        # Randomize camera position and orientation\n        pos_min, pos_max = self.domain_params['camera']['position_range']\n        position = [\n            random.uniform(pos_min[0], pos_max[0]),\n            random.uniform(pos_min[1], pos_max[1]),\n            random.uniform(pos_min[2], pos_max[2])\n        ]\n\n        angle_min, angle_max = self.domain_params['camera']['angle_range']\n        orientation = [\n            random.uniform(angle_min[0], angle_max[0]),\n            random.uniform(angle_min[1], angle_max[1]),\n            random.uniform(angle_min[2], angle_max[2])\n        ]\n\n        # Apply noise\n        noise_level = random.uniform(*self.domain_params['camera']['noise_level_range'])\n\n        self.camera.set_world_pose(position=np.array(position))\n\n        self.get_logger().debug(f'Applied random camera: pos={position}, noise={noise_level}')\n\n    def randomize_environment(self):\n        \"\"\"Apply random environmental conditions\"\"\"\n        floor_texture = random.choice(self.domain_params['environment']['floor_textures'])\n        background_obj = random.choice(self.domain_params['environment']['background_objects'])\n\n        self.get_logger().debug(f'Applied random environment: floor={floor_texture}, bg_obj={background_obj}')\n\n    def generate_sample(self, sample_id: int) -> Dict[str, Any]:\n        \"\"\"Generate a single synthetic data sample\"\"\"\n        try:\n            # Apply domain randomization\n            self.randomize_lighting()\n            self.randomize_materials()\n            self.randomize_camera()\n            self.randomize_environment()\n\n            # Step the simulation to apply changes\n            self.world.step(render=True)\n\n            # Capture RGB image\n            rgb_image = self.camera.get_rgb()\n\n            # Capture depth image\n            depth_image = self.camera.get_depth()\n\n            # Capture segmentation mask (if available)\n            try:\n                segmentation = self.camera.get_segmentation()\n            except:\n                segmentation = np.zeros_like(rgb_image[:, :, 0])\n\n            # Create metadata\n            metadata = {\n                'sample_id': sample_id,\n                'timestamp': datetime.datetime.now().isoformat(),\n                'camera_pose': self.camera.get_world_pose(),\n                'domain_params': {\n                    'lighting_intensity': random.uniform(*self.domain_params['lighting']['intensity_range']),\n                    'material_reflectance': random.uniform(*self.domain_params['materials']['reflectance_range']),\n                    'camera_noise': random.uniform(*self.domain_params['camera']['noise_level_range'])\n                }\n            }\n\n            # Save images\n            rgb_path = os.path.join(self.output_dir, \"images\", f\"rgb_{sample_id:06d}.png\")\n            depth_path = os.path.join(self.output_dir, \"images\", f\"depth_{sample_id:06d}.png\")\n            seg_path = os.path.join(self.output_dir, \"labels\", f\"seg_{sample_id:06d}.png\")\n            meta_path = os.path.join(self.output_dir, \"metadata\", f\"meta_{sample_id:06d}.json\")\n\n            # Save RGB image\n            Image.fromarray(rgb_image).save(rgb_path)\n\n            # Save depth image (normalize for 16-bit PNG)\n            depth_normalized = ((depth_image - depth_image.min()) / (depth_image.max() - depth_image.min()) * 65535).astype(np.uint16)\n            Image.fromarray(depth_normalized).save(depth_path)\n\n            # Save segmentation mask\n            Image.fromarray(segmentation).save(seg_path)\n\n            # Save metadata\n            with open(meta_path, 'w') as f:\n                json.dump(metadata, f, indent=2)\n\n            return {\n                'rgb_path': rgb_path,\n                'depth_path': depth_path,\n                'seg_path': seg_path,\n                'meta_path': meta_path,\n                'metadata': metadata\n            }\n\n        except Exception as e:\n            self.get_logger().error(f'Error generating sample {sample_id}: {e}')\n            return None\n\n    def generate_dataset(self):\n        \"\"\"Generate the complete synthetic dataset\"\"\"\n        self.get_logger().info(f'Generating {self.num_samples} synthetic samples...')\n\n        generated_samples = []\n\n        for i in range(self.num_samples):\n            sample_data = self.generate_sample(i)\n            if sample_data:\n                generated_samples.append(sample_data)\n\n                if (i + 1) % 100 == 0:\n                    self.get_logger().info(f'Generated {i + 1}/{self.num_samples} samples')\n\n        # Create dataset manifest\n        manifest = {\n            'dataset_name': 'Humanoid_Robot_Synthetic_Data',\n            'total_samples': len(generated_samples),\n            'generated_at': datetime.datetime.now().isoformat(),\n            'domain_parameters': self.domain_params,\n            'sample_paths': [s['meta_path'] for s in generated_samples if s]\n        }\n\n        manifest_path = os.path.join(self.output_dir, 'dataset_manifest.json')\n        with open(manifest_path, 'w') as f:\n            json.dump(manifest, f, indent=2)\n\n        self.get_logger().info(f'Dataset generation complete. Total samples: {len(generated_samples)}')\n        return generated_samples\n\n# ROS 2 node for synthetic data generation workflow\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Int32\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport threading\nimport queue\n\nclass SyntheticDataROSNode(Node):\n    def __init__(self):\n        super().__init__('synthetic_data_ros_node')\n\n        # Initialize CV bridge\n        self.cv_bridge = CvBridge()\n\n        # Publishers for synthetic data\n        self.rgb_pub = self.create_publisher(Image, '/synthetic/rgb', 10)\n        self.depth_pub = self.create_publisher(Image, '/synthetic/depth', 10)\n        self.status_pub = self.create_publisher(String, '/synthetic/status', 10)\n\n        # Subscribers for control\n        self.start_sub = self.create_subscription(\n            String, '/synthetic/start_generation', self.start_generation_callback, 10\n        )\n        self.progress_sub = self.create_subscription(\n            Int32, '/synthetic/progress', self.progress_callback, 10\n        )\n\n        # Generation parameters\n        self.generation_params = {\n            'num_samples': 1000,\n            'output_dir': '/tmp/synthetic_data',\n            'domain_randomization': True\n        }\n\n        # Generation control\n        self.generation_active = False\n        self.generation_thread = None\n\n        # Data queue for publishing\n        self.data_queue = queue.Queue(maxsize=10)\n\n        self.get_logger().info('Synthetic Data ROS Node initialized')\n\n    def start_generation_callback(self, msg):\n        \"\"\"Start synthetic data generation\"\"\"\n        try:\n            params = json.loads(msg.data) if msg.data else {}\n            self.generation_params.update(params)\n\n            if not self.generation_active:\n                self.generation_active = True\n                self.generation_thread = threading.Thread(target=self._run_generation)\n                self.generation_thread.start()\n\n                status_msg = String()\n                status_msg.data = f'Started generation: {self.generation_params[\"num_samples\"]} samples'\n                self.status_pub.publish(status_msg)\n            else:\n                self.get_logger().warn('Generation already active')\n\n        except Exception as e:\n            self.get_logger().error(f'Error starting generation: {e}')\n\n    def _run_generation(self):\n        \"\"\"Run the actual generation in a separate thread\"\"\"\n        try:\n            # Create synthetic data generator\n            generator = IsaacSyntheticDataGenerator(\n                output_dir=self.generation_params['output_dir'],\n                num_samples=self.generation_params['num_samples']\n            )\n\n            # Generate dataset\n            samples = generator.generate_dataset()\n\n            # Update status\n            status_msg = String()\n            status_msg.data = f'Generation complete: {len(samples)} samples'\n            self.status_pub.publish(status_msg)\n\n        except Exception as e:\n            self.get_logger().error(f'Generation error: {e}')\n        finally:\n            self.generation_active = False\n\n    def progress_callback(self, msg):\n        \"\"\"Handle progress updates\"\"\"\n        progress = msg.data\n        self.get_logger().info(f'Generation progress: {progress}%')\n\n    def publish_synthetic_data(self, rgb_image, depth_image):\n        \"\"\"Publish synthetic data to ROS topics\"\"\"\n        try:\n            # Convert numpy arrays to ROS Image messages\n            rgb_ros = self.cv_bridge.cv2_to_imgmsg(rgb_image, encoding=\"rgb8\")\n            depth_ros = self.cv_bridge.cv2_to_imgmsg(depth_image, encoding=\"32FC1\")\n\n            # Add timestamps\n            current_time = self.get_clock().now().to_msg()\n            rgb_ros.header.stamp = current_time\n            depth_ros.header.stamp = current_time\n            rgb_ros.header.frame_id = 'synthetic_camera'\n            depth_ros.header.frame_id = 'synthetic_camera'\n\n            # Publish images\n            self.rgb_pub.publish(rgb_ros)\n            self.depth_pub.publish(depth_ros)\n\n        except Exception as e:\n            self.get_logger().error(f'Error publishing synthetic data: {e}')\n\ndef main(args=None):\n    \"\"\"Main function for synthetic data generation\"\"\"\n    # In a real Isaac Sim extension, this would be integrated differently\n    # This example shows how the ROS integration component would work\n\n    rclpy.init(args=args)\n    synthetic_node = SyntheticDataROSNode()\n\n    try:\n        # Run the ROS node\n        rclpy.spin(synthetic_node)\n    except KeyboardInterrupt:\n        synthetic_node.get_logger().info('Shutting down synthetic data node')\n    finally:\n        synthetic_node.destroy_node()\n        rclpy.shutdown()\n\n# Isaac Sim Extension for Synthetic Data Generation\nclass IsaacSyntheticDataExtension:\n    def __init__(self):\n        self._world = None\n        self._data_generator = None\n        self._generation_active = False\n\n    def on_startup(self, ext_id):\n        \"\"\"Called when the extension is started\"\"\"\n        carb.log_info(\"[isaac_synthetic_data] Isaac Synthetic Data Generator starting...\")\n\n    def on_shutdown(self):\n        \"\"\"Called when the extension is shut down\"\"\"\n        carb.log_info(\"[isaac_synthetic_data] Isaac Synthetic Data Generator shutting down...\")\n\n        if self._generation_active:\n            self.stop_generation()\n\n    def start_generation(self, output_dir: str, num_samples: int, domain_params: Dict):\n        \"\"\"Start synthetic data generation\"\"\"\n        try:\n            self._data_generator = IsaacSyntheticDataGenerator(\n                output_dir=output_dir,\n                num_samples=num_samples\n            )\n\n            # Update domain parameters\n            self._data_generator.domain_params.update(domain_params)\n\n            # Start generation in a separate thread\n            import threading\n            gen_thread = threading.Thread(target=self._data_generator.generate_dataset)\n            gen_thread.start()\n\n            self._generation_active = True\n            carb.log_info(f\"[isaac_synthetic_data] Started generation: {num_samples} samples to {output_dir}\")\n\n        except Exception as e:\n            carb.log_error(f\"[isaac_synthetic_data] Error starting generation: {e}\")\n\n    def stop_generation(self):\n        \"\"\"Stop synthetic data generation\"\"\"\n        self._generation_active = False\n        carb.log_info(\"[isaac_synthetic_data] Stopped generation\")\n"})}),"\n",(0,i.jsx)(n.h2,{id:"diagrams",children:"Diagrams"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Synthetic Data Generation Pipeline:\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Domain         \u2502    \u2502  Isaac Sim      \u2502    \u2502  Data           \u2502\n\u2502  Randomization  \u2502\u2500\u2500\u2500\u25ba\u2502  Simulation     \u2502\u2500\u2500\u2500\u25ba\u2502  Collection &   \u2502\n\u2502  (Lighting,     \u2502    \u2502  (Physics,      \u2502    \u2502  Annotation     \u2502\n\u2502   Materials,     \u2502    \u2502   Rendering)    \u2502    \u2502                 \u2502\n\u2502   Camera, etc.)  \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Isaac ROS Integration                        \u2502\n\u2502                    (ROS 2 Bridge for Control)                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u25bc\n                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502  Dataset        \u2502\n                       \u2502  (Images,       \u2502\n                       \u2502   Labels, Meta)  \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nDomain Randomization Strategy:\n\nBase Scene \u2500\u2500\u252c\u2500\u2500\u25ba Lighting Randomization \u2500\u2500\u25ba Diverse Illumination\n             \u251c\u2500\u2500\u25ba Material Randomization \u2500\u2500\u25ba Varied Textures/Colors\n             \u251c\u2500\u2500\u25ba Camera Randomization \u2500\u2500\u2500\u2500\u25ba Different Viewpoints\n             \u2514\u2500\u2500\u25ba Environment Randomization \u2500\u25ba Multiple Scenarios\n\nSynthetic-to-Real Transfer:\n\nHigh Domain   \u2500\u2500\u25ba  Robust AI Models  \u2500\u2500\u25ba  Better Real-World\nRandomization         (Generalized)         Performance\n"})}),"\n",(0,i.jsx)(n.h2,{id:"case-study",children:"Case Study"}),"\n",(0,i.jsx)(n.p,{children:"The NVIDIA Isaac team has demonstrated the effectiveness of synthetic data generation for training humanoid robot perception systems. In one example, they used Isaac Sim to generate over 100,000 synthetic images of a humanoid robot in various poses and environments, with randomized lighting, materials, and camera parameters. The synthetic-trained models achieved comparable performance to real-data-trained models when tested on actual robot hardware, while reducing data collection time from months to hours. This approach has enabled faster development cycles and more robust AI models for humanoid robots operating in diverse environments."}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/tutorial_advanced_synthetic_data.html",children:"Isaac Sim Synthetic Data Generation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization in Robotics"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://developer.nvidia.com/blog/generating-synthetic-data-for-ai-training-with-isaac-sim/",children:"Synthetic Data for Robotics Applications"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"What are the main benefits of synthetic data generation for robotics?"}),"\n",(0,i.jsx)(n.li,{children:"How does domain randomization improve model robustness?"}),"\n",(0,i.jsx)(n.li,{children:"What are the challenges in synthetic-to-real transfer?"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"practical-exercises",children:"Practical Exercises"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Configure Isaac Sim for synthetic data generation"}),"\n",(0,i.jsx)(n.li,{children:"Implement domain randomization for lighting conditions"}),"\n",(0,i.jsx)(n.li,{children:"Generate a synthetic dataset for object detection"}),"\n",(0,i.jsx)(n.li,{children:"Compare synthetic-trained models with real-data-trained models"}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(m,{...e})}):m(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var t=a(6540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);